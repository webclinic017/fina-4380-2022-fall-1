{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# McKinney Chapter 10 - Data Aggregation and Group Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Chapter 10 of Wes McKinney's [*Python for Data Analysis*](https://wesmckinney.com/pages/book.html) discusses groupby operations, which are the pandas equivalent of Excel pivot tables.\n",
    "Pivot tables help us calculate statistics (e.g., sum, mean, and median) for one set of variables by groups of other variables (e.g., weekday or year).\n",
    "For example, we could use a pivot table to calculate mean daily stock returns by weekday.\n",
    "\n",
    "We will focus on:\n",
    "\n",
    "1. Using `.groupby()` to group by columns, indexes, and functions\n",
    "1. Using `.agg()` to aggregate multiple functions\n",
    "1. Using pivot tables as an alternative to `.groupby()`\n",
    "\n",
    "***Note:*** Indented block quotes are from McKinney, and section numbers differ from McKinney because we will not discuss every topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 150\n",
    "%precision 4\n",
    "pd.options.display.float_format = '{:.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yfinance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests_cache\u001b[39;00m\n\u001b[1;32m      2\u001b[0m session \u001b[38;5;241m=\u001b[39m requests_cache\u001b[38;5;241m.\u001b[39mCachedSession(expire_after\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1D\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myfinance\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01myf\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas_datareader\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpdr\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yfinance'"
     ]
    }
   ],
   "source": [
    "import requests_cache\n",
    "session = requests_cache.CachedSession(expire_after='1D')\n",
    "import yfinance as yf\n",
    "import pandas_datareader as pdr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GroupBy Mechanics\n",
    "\n",
    "\"Split-apply-combine\" is an excellent way to describe and visualize pandas groupby operations.\n",
    "\n",
    "> Hadley Wickham, an author of many popular packages for the R programming \n",
    "language, coined the term split-apply-combine for describing group operations. In the\n",
    "first stage of the process, data contained in a pandas object, whether a Series, DataFrame, or otherwise, is split into groups based on one or more keys that you provide.\n",
    "The splitting is performed on a particular axis of an object. For example, a DataFrame\n",
    "can be grouped on its rows (axis=0) or its columns (axis=1). Once this is done, a\n",
    "function is applied to each group, producing a new value. Finally, the results of all\n",
    "those function applications are combined into a result object. The form of the resulting object will usually depend on whatâ€™s being done to the data. See Figure 10-1 for a\n",
    "mockup of a simple group aggregation.\n",
    "\n",
    "Figure 10-1 visualizes a pandas groupby operation that:\n",
    "\n",
    "1. Splits the dataframe by the `key` column (i.e., \"groups by `key`\")\n",
    "2. Applies the sum operation to the `data` column (i.e., \"sums `data`\")\n",
    "3. Combines the grouped sums\n",
    "\n",
    "I describe this operation as \"sum the `data` column by (gruops formed on) the `key` column.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "df = pd.DataFrame({'key1' : ['a', 'a', 'b', 'b', 'a'],\n",
    "                   'key2' : ['one', 'two', 'one', 'two', 'one'],\n",
    "                   'data1' : np.random.randn(5),\n",
    "                   'data2' : np.random.randn(5)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is one way to calculate the means of `data1` by (grouops formed on) `key1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['key1'] == 'a', 'data1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['key1'] == 'b', 'data1'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this calculation more quickly:\n",
    "\n",
    "1. Use the `.groupby()` method to group by `key1`\n",
    "2. Use the `.mean()` method to sum `data1` within each value of `key1`\n",
    "\n",
    "Note that without the `.mean()` method, pandas only sets up the grouped object, which can accept the `.mean()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "grouped = df['data1'].groupby(df['key1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "grouped.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can can chain the `.groupby()` and `.mean()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['data1'].groupby(df['key1']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we prefer our result as a dataframe instead of a series, we can wrap `data1` with two sets of square brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['data1']].groupby(df['key1']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can group by more than one variable.\n",
    "We get a hierarchical row index (or row multi-index) when we group by more than one variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "means = df['data1'].groupby([df['key1'], df['key2']]).mean()\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `.unstack()` method if we want to use both rows and columns to organize data.\n",
    "Note that, the `.unstack()` method un-stacks the last dimension (i.e., `level = -1`) by default so that `key2` values become columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "means.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grouping variables can also be columns in the data frame passed to the `.groupby()` method.\n",
    "I prefer this approach because we will typically have all data in one data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.groupby('key1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['key1', 'key2']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many more methods than `.mean()`.\n",
    "We can use tab completion to discover (or remind ourselves of) these other methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating Over Groups\n",
    "\n",
    "We can iterate over groups, too.\n",
    "The `.groupby()` method generates a sequence of tuples.\n",
    "Each tuples contains the value(s) of the grouping variable(s) and associated chunk of the dataframe.\n",
    "McKinney provides two loops to show how to iterate over groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for name, group in df.groupby('key1'):\n",
    "    print(name)\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for (k1, k2), group in df.groupby(['key1', 'key2']):\n",
    "    print((k1, k2))\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Selecting a Column or Subset of Columns\n",
    "\n",
    "We preview the idea of grouping an entire dataframe above.\n",
    "However, I want to take this chance to explain McKinney's use of the phrase \"syntactic sugar.\"\n",
    "Here is the context:\n",
    "\n",
    "> Indexing a GroupBy object created from a DataFrame with a column name or array\n",
    "of column names has the effect of column subsetting for aggregation. This means\n",
    "that:\n",
    ">\n",
    "> ```\n",
    "> df.groupby('key1')['data1']\n",
    "> df.groupby('key1')[['data2']]\n",
    "> ```\n",
    ">\n",
    "> are syntactic sugar for\n",
    ">\n",
    "> ```\n",
    "> df['data1'].groupby(df['key1'])\n",
    "> df[['data2']].groupby(df['key1'])\n",
    "> ```\n",
    "\n",
    "\"Syntactic sugar\" makes code easier to type or read without adding functionality.\n",
    "It makes code \"sweeter\" for humans to type or read by making it more concise or clear.\n",
    "The implication is that syntactic sugar makes code faster to type/read but does make code faster to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.groupby(['key1', 'key2'])[['data2']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping with Functions\n",
    "\n",
    "We can also group with functions.\n",
    "Below, we group with the `len` function, which calculates the length of the first names in the row index.\n",
    "We could instead add a helper column to `people`, but it is easier to pass a function to `.groupby()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "people = pd.DataFrame(\n",
    "    data=np.random.randn(5, 5), \n",
    "    columns=['a', 'b', 'c', 'd', 'e'], \n",
    "    index=['Joe', 'Steve', 'Wes', 'Jim', 'Travis']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "people.groupby(len).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can mix functions, lists, etc. that we pass to `.groupby()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "key_list = ['one', 'one', 'one', 'two', 'two']\n",
    "people.groupby([len, key_list]).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Joe': 'a', 'Jim': 'b'}\n",
    "people.groupby([len, d]).min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping by Index Levels\n",
    "\n",
    "We can also group by index levels.\n",
    "We can specify index levels by either level number or name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "columns = pd.MultiIndex.from_arrays([['US', 'US', 'US', 'JP', 'JP'],\n",
    "                                    [1, 3, 5, 1, 3]],\n",
    "                                    names=['cty', 'tenor'])\n",
    "hier_df = pd.DataFrame(np.random.randn(4, 5), columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hier_df.groupby(level='cty', axis=1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "hier_df.groupby(level='cty', axis='columns').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "hier_df.groupby(level='tenor', axis=1).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Aggregation\n",
    "\n",
    "Table 10-1 provides the optimized groupby methods:\n",
    "\n",
    "- `count`: Number of non-NA values in the group\n",
    "- `sum`: Sum of non-NA values\n",
    "- `mean`: Mean of non-NA values\n",
    "- `median`: Arithmetic median of non-NA values\n",
    "- `std`, `var`: Unbiased (n â€“ 1 denominator) standard deviation and variance\n",
    "- `min`, `max`: Minimum and maximum of non-NA values\n",
    "- `prod`: Product of non-NA values\n",
    "- `first`, `last`: First and last non-NA values\n",
    "\n",
    "These optimized methods are fast and efficient, but pandas does not limit us to these methods.\n",
    "First, any series method is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key1')['data1'].quantile(0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we can write our own functions and pass them to the `.agg()` method.\n",
    "These functions should accept an array and returns a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def peak_to_peak(arr):\n",
    "    return arr.max() - arr.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key1')['data1'].agg(peak_to_peak)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some other methods work, too, even if they are do not aggregate an array to a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.groupby('key1')['data1'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column-Wise and Multiple Function Application\n",
    "\n",
    "The `.agg()` methods provides two more handy features:\n",
    "\n",
    "1. We can pass multiple functions to operate on all of the columns\n",
    "2. We can pass specific functions to operate on specific columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply: General split-apply-combine\n",
    "\n",
    "The `.agg()` method aggrates an array to a single value.\n",
    "We can use the `.apply()` method for more general calculations.\n",
    "\n",
    "We can combine the `.groupby()` and `.apply()` methods to:\n",
    "\n",
    "1. Split a dataframe by grouping variables\n",
    "2. Call the applied function on each chunk of the original dataframe\n",
    "3. Recombine the output of the applied function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top(x, col, n=1):\n",
    "    return x.sort_values(col).head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key1').apply(top, col='data1', n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key1').apply(top, col='data2', n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pivot Tables and Cross-Tabulation\n",
    "\n",
    "Above we manually made pivot tables with the `groupby()`, `.agg()`, `.apply()` and `.unstack()` methods.\n",
    "pandas provides a literal interpreation of Excel-style pivot tables with the `.pivot_table()` method and the `pandas.pivot_table()` function.\n",
    "These also provide row and column totals via \"margins\".\n",
    "It is worthwhile to read-through the `.pivot_table()` docstring several times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = (\n",
    "    yf.download(tickers='^GSPC ^DJI ^IXIC ^FTSE ^N225 ^HSI', session=session)\n",
    "    .rename_axis(columns=['Variable', 'Index'])\n",
    "    .stack()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default aggregation function for `.pivot_table()` is `mean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind.loc['2015':].pivot_table(index='Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use \n",
    "    `values` to select specific variables, \n",
    "    `pd.Grouper()` to sample different date windows, \n",
    "    and \n",
    "    `aggfunc` to select specific aggregation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ind\n",
    "    .loc['2015':]\n",
    "    .reset_index()\n",
    "    .pivot_table(\n",
    "        values='Close',\n",
    "        index=pd.Grouper(key='Date', freq='A'),\n",
    "        columns='Index',\n",
    "        aggfunc=['min', 'max']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "df = pd.DataFrame({'key1' : ['a', 'a', 'b', 'b', 'a'],\n",
    "                   'key2' : ['one', 'two', 'one', 'two', 'one'],\n",
    "                   'data1' : np.random.randn(5),\n",
    "                   'data2' : np.random.randn(5)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Practice:***\n",
    "Calculate the means of columns `data1` and `data2` by `key1` and `key2`, and arrange the results so that values of `key1` are in the rows and values of `key2` are in the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Practice:***\n",
    "Replicate the previous practice exercise with `pd.pivot_table()` and test equality with `np.allclose()`.\n",
    "We will learn more about `pd.pivot_table()` at the end of this notebook, but we can give it a try now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "people = pd.DataFrame(\n",
    "    data=np.random.randn(5, 5), \n",
    "    columns=['a', 'b', 'c', 'd', 'e'], \n",
    "    index=['Joe', 'Steve', 'Wes', 'Jim', 'Travis']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Practice:***\n",
    "Calculate the sum of columns `a` through `e` by groups formed on the last letter in each name.\n",
    "*Hint:* use an anonymous (lambda) function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Practice:***\n",
    "Use the `.to_clipboard()` method to check your answer to the previous practice exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need data for the following two practice exercises.\n",
    "We have to jump through some hoops with `pd.MultiIndex.from_product()` if we want to take full advantage of pandas multi indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang = yf.download(tickers='META AAPL AMZN NFLX GOOG', session=session)\n",
    "faang.columns.names = ['Variable', 'Ticker']\n",
    "faang[pd.MultiIndex.from_product([['Return'], faang['Adj Close'].columns])] = faang['Adj Close'].pct_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Practice:***\n",
    "For the FAANG stocks, calulate the mean and standard deviation of returns by ticker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Practice:***\n",
    "For the FAANG stocks, calulate the mean and standard deviation of returns and the maximum of closing prices by ticker.\n",
    "To do this, pass a dictionary where the keys are the column names and the values are lists of functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Practice:***\n",
    "\n",
    "1. Download all available daily data for the S&P 500 ETF and Google stock (tickers SPY and GOOG)\n",
    "2. Calculate daily returns\n",
    "3. Calculate the volatility (standard deviation) of daily returns *every month* by combining `pd.Grouper()` and `.groupby()`)\n",
    "4. Multiply by $\\sqrt{252}$ to annualize these volatilities of daily returns\n",
    "5. Plot these annualized volatilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Practice:***\n",
    "\n",
    "1. Download the daily factor data from Ken French's website\n",
    "1. Calculate daily market returns by summing the market risk premium and risk-free rates (`Mkt-RF` and `RF`, respectively)\n",
    "1. Calculate the volatility (standard deviation) of daily returns *every month* by combining `pd.Grouper()` and `.groupby()`)\n",
    "1. Multiply by $\\sqrt{252}$ to annualize these volatilities of daily returns\n",
    "1. Plot these annualized volatilities\n",
    "\n",
    "Is market volatility higher during wars?\n",
    "Consider the following dates:\n",
    "\n",
    "1. WWII: December 1941 to September 1945\n",
    "1. Korean War: 1950 to 1953\n",
    "1. Viet Nam War: 1959 to 1975\n",
    "1. Gulf War: 1990 to 1991\n",
    "1. War in Afghanistan: 2001 to 2021"
   ]
  }
 ],
 "metadata": {
  "author": "Richard Herron",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "title": "McKinney Chapter 10 - Data Aggregation and Group Operations",
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}