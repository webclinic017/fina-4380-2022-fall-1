{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lewinson Chapter 6: Monte Carlo Simulations in Finance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Chapter 6 of Eryk Lewinson's [*Python for Finance Cookbook*](https://www.packtpub.com/product/python-for-finance-cookbook/9781789618518) introduces simulation techniques.\n",
    "\n",
    "We will focus on:\n",
    "\n",
    "1. Simulating stock prices\n",
    "1. Pricing European options with these simulated stock prices\n",
    "1. Calculating value at risk (VaR)\n",
    "\n",
    "***Note:*** Indented block quotes are from Lewinson, and section numbers differ from Lewinson because we will not discuss every topic.\n",
    "\n",
    "I will simplify and streamline his code, where possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "%precision 4\n",
    "pd.options.display.float_format = '{:.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests_cache\n",
    "session = requests_cache.CachedSession(expire_after='1D')\n",
    "import yfinance as yf\n",
    "import pandas_datareader as pdr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Monte Carlo simulations are a class of computational algorithms that use repeated random sampling to solve any problems that have a probabilistic interpretation. In finance, one of the reasons they gained popularity is that they can be used to accurately estimate integrals. The main idea of Monte Carlo simulations is to produce a multitude of sample paths—possible scenarios/outcomes, often over a given period of time. The horizon is then split into a specified number of time steps and the process of doing so is called discretization. Its goal is to approximate continuous time, since the pricing of financial instruments happens in continuous time.\n",
    ">\n",
    "> The results from all these simulated sample paths can be used to calculate metrics such as the percentage of times an event occurred, the average value of an instrument at the last step, and so on. Historically, the main problem with the Monte Carlo approach was that it required heavy computational power to calculate all possible scenarios. Nowadays, it is becoming less of a problem as we can run fairly advanced simulations on a desktop computer or a laptop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating stock price dynamics using Geometric Brownian Motion\n",
    "\n",
    "> Thanks to the unpredictability of financial markets, simulating stock prices plays an important role in the valuation of many derivatives, such as options. Due to the aforementioned randomness in price movement, these simulations rely on stochastic differential equations (SDE).\n",
    "> \n",
    "> A stochastic process is said to follow the Geometric Brownian Motion (GBM) when it satisfies the following SDE: $$dS = \\mu S dt + \\sigma S dW_t$$\n",
    "> \n",
    "> Here, we have the following:\n",
    "> \n",
    "> - $S$: Stock price\n",
    "> - $\\mu$: The drift coefficient, that is, the average return over a given period or the instantaneous expected return\n",
    "> - $\\sigma$: The diffusion coefficient, that is, how much volatility is in the drift\n",
    "> - $W_t$: The Brownian Motion\n",
    "> \n",
    "> We will not investigate the properties of the Brownian Motion in too much depth, as it is outside the scope of this book. Suffice to say, Brownian increments are calculated as a product of a Standard Normal random variable ($rv ∼ N(0,1)$) and the square root of the time increment. Another way to say this is that the Brownian increment comes from $rv ∼ N(0,t)$, where $t$ is the time increment. We obtain the Brownian path by taking the cumulative sum of the Brownian increments.\n",
    "> \n",
    "> The SDE has a closed-form solution (only a few SDEs have it): $$S(t) = S_0 \\exp\\left(\\left(\\mu - \\frac{1}{2}\\sigma^2\\right)t + \\sigma W_t\\right)$$\n",
    "> \n",
    "> Here, $S_0 = S(0)$ is the initial value of the process, which in this case is the initial price of a stock. The preceding equation presents the relationship compared to the initial stock price.\n",
    "> \n",
    "> For simulations, we can use the following recursive formula: $$S(t_{i+1}) = S(t_i) \\exp\\left(\\left(\\mu - \\frac{1}{2}\\sigma^2\\right)(t_{i+1} - t_i) + \\sigma \\sqrt{t_{i+1} - t_i} Z_{i+1}\\right)$$\n",
    "> \n",
    "> Here, $Z_i$ is a Standard Normal random variable and $i = 0, \\ldots, T-1$ is the time index. This specification is possible because the increments of W are independent and normally distributed.\n",
    "> \n",
    "> *GBM is a process that does not account for mean-reversion and time-dependent volatility. That is why it is often used for stocks and not for bond prices, which tend to display long-term reversion to the face value.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T19:33:09.445364Z",
     "start_time": "2020-01-27T19:33:04.878110Z"
    }
   },
   "outputs": [],
   "source": [
    "df = yf.download(tickers='MSFT', session=session)\n",
    "df['Return'] = df['Adj Close'].pct_change()\n",
    "returns = df.loc['2019', 'Return']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the first ten months to \"train\" and the last two months to \"test\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T19:34:10.462993Z",
     "start_time": "2020-01-27T19:34:10.456614Z"
    }
   },
   "outputs": [],
   "source": [
    "train = returns[:'2019-10-31']\n",
    "test = returns['2019-11-01':]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the training sample to estimate parameters, like $\\mu$ and $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T19:34:18.797009Z",
     "start_time": "2020-01-27T19:34:18.792234Z"
    }
   },
   "outputs": [],
   "source": [
    "T = len(test)\n",
    "N = len(test)\n",
    "S_0 = df.loc[train.index[-1], 'Adj Close']\n",
    "N_SIM = 100\n",
    "mu = train.mean()\n",
    "sigma = train.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Lewinson's `simulate_gbm()` function for simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T19:36:24.009581Z",
     "start_time": "2020-01-27T19:36:24.003387Z"
    }
   },
   "outputs": [],
   "source": [
    "def simulate_gbm(s_0, mu, sigma, n_sims, T, N, random_seed=42):\n",
    "    '''\n",
    "    Function used for simulating stock returns using Geometric Brownian Motion.\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    s_0 : float\n",
    "        Initial stock price\n",
    "    mu : float\n",
    "        Drift coefficient\n",
    "    sigma : float\n",
    "        Diffusion coefficient\n",
    "    n_sims : int\n",
    "        Number of simulations paths\n",
    "    dt : float\n",
    "        Time increment, most commonly a day\n",
    "    T : float\n",
    "        Length of the forecast horizon, same unit as dt\n",
    "    N : int\n",
    "        Number of time increments in the forecast horizon\n",
    "    random_seed : int\n",
    "        Random seed for reproducibility\n",
    "\n",
    "    Returns\n",
    "    -----------\n",
    "    S_t : np.ndarray\n",
    "        Matrix (size: n_sims x (T+1)) containing the simulation results. \n",
    "        Rows respresent sample paths, while columns point of time.\n",
    "    '''\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    dt = T / N\n",
    "    dW = np.random.normal(scale = np.sqrt(dt), size=(n_sims, N))\n",
    "    W = np.cumsum(dW, axis=1)\n",
    "    \n",
    "    time_step = np.linspace(dt, T, N)\n",
    "    time_steps = np.broadcast_to(time_step, (n_sims, N))\n",
    "    \n",
    "    S_t = s_0 * np.exp((mu - 0.5 * sigma**2) * time_steps + sigma * W)\n",
    "    S_t = np.insert(S_t, 0, s_0, axis=1)\n",
    "    \n",
    "    return S_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we run the simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "gbm_simulations = pd.DataFrame(\n",
    "    data=simulate_gbm(S_0, mu, sigma, N_SIM, T, N).T,\n",
    "    index=returns.loc[train.index[-1]:].index,\n",
    "    columns=pd.Index(data=range(1, N_SIM + 1), name='Simulation')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, plot the simulation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T19:36:33.813773Z",
     "start_time": "2020-01-27T19:36:26.823553Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(gbm_simulations, alpha=0.2, label='_nolegend_') # use plt.plot to omit lines from legend\n",
    "plt.plot(gbm_simulations.mean(axis=1), label='Simulated Mean')\n",
    "plt.plot(df.loc[gbm_simulations.index, 'Adj Close'], label='Observed')\n",
    "plt.legend()\n",
    "plt.ylabel('Price ($)')\n",
    "plt.xlabel('Date')\n",
    "plt.xticks(rotation=45) # but plt.plot() does not provide smart ticks\n",
    "plt.title(\n",
    "    'MSFT Simulated Prices\\n' + \n",
    "    'Trained from {} to {}'.format(returns.index[0].strftime('%Y-%m-%d'), returns.index[-1].strftime('%Y-%m-%d'))\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average simulation is very close to the observed truth!\n",
    "The *average* average simulation should be close to the *average* observed truth (if the training period is similar to the test period).\n",
    "However, this will not always be true.\n",
    "We will repeat the exercise above for 2018 to see that average simulation predicts the truth on average (if the training period is similar to the test period) but does not predict every future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pricing European Options using Simulations \n",
    "\n",
    "> Options are a type of derivative instrument because their price is linked to the price of the underlying security, such as stock. Buying an options contract grants the right, but not the obligation, to buy or sell an underlying asset at a set price (known as a strike) on/before a certain date. The main reason for the popularity of options is because they hedge away exposure to an asset's price moving in an undesirable way.\n",
    "> \n",
    "> A European call/put option gives us the right (but again, no obligation) to buy/sell a certain asset on a certain expiry date (commonly denoted as $T$).\n",
    "> \n",
    "> Some popular methods of options' valuation:\n",
    "> \n",
    "> - Using analytic formulas\n",
    "> - Binomial tree approach\n",
    "> - Finite differences\n",
    "> - Monte Carlo simulations\n",
    ">\n",
    "> European options are an exception in the sense that there exist an analytical formula for their valuation, which is not the case for more advanced derivatives, such as American or Exotic options.\n",
    "> \n",
    "> To price options using Monte Carlo simulations, we use risk-neutral valuation, under which the fair value of a derivative is the expected value of its future payoff(s). In other words, we assume that the option premium grows at the same rate as the risk-free rate, which we use for discounting to the present value. For each of the simulated paths, we calculate the option's payoff at maturity, take the average of all the paths, and discount it to the present value.\n",
    "> \n",
    "> In this recipe, we show how to code the closed-form solution to the Black-Scholes model and then use the simulation approach. For simplicity, we use fictitious input data, but real-life data could be used analogically.\n",
    "\n",
    "We will use `norm()` from SciPy to estimate cumulative distribution functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T20:09:31.912459Z",
     "start_time": "2020-01-27T20:09:31.324143Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Lewinson's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T20:09:32.297916Z",
     "start_time": "2020-01-27T20:09:32.293721Z"
    }
   },
   "outputs": [],
   "source": [
    "S_0 = 100\n",
    "K = 100\n",
    "r = 0.05\n",
    "sigma = 0.50\n",
    "T = 1 # 1 year\n",
    "N = 252 # 252 days in a year\n",
    "dt = T / N # time step\n",
    "N_SIMS = 1000000 # number of simulations \n",
    "discount_factor = np.exp(-r * T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an analytical solution to European options (i.e., the Black and Scholes (1973) formula)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T20:09:32.919121Z",
     "start_time": "2020-01-27T20:09:32.911916Z"
    }
   },
   "outputs": [],
   "source": [
    "def black_scholes_analytical(S_0, K, T, r, sigma, type='call'):\n",
    "    '''\n",
    "    Function used for calculating the price of European options using the analytical form of the Black-Scholes model.\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    s_0 : float\n",
    "        Initial stock price\n",
    "    K : float\n",
    "        Strike price\n",
    "    T : float\n",
    "        Time to maturity in years\n",
    "    r : float\n",
    "        Annualized risk-free rate\n",
    "    sigma : float\n",
    "        Standard deviation of the stock returns\n",
    "    type : str\n",
    "        Type of the option. Allowable: ['call', 'put']\n",
    "    \n",
    "    Returns\n",
    "    -----------\n",
    "    option_premium : float\n",
    "        The premium on the option calculated using the Black-Scholes model\n",
    "    '''\n",
    "    \n",
    "    d1 = (np.log(S_0 / K) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n",
    "    d2 = (np.log(S_0 / K) + (r - 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n",
    "    \n",
    "    if type == 'call':\n",
    "        val = (S_0 * norm.cdf(d1, 0, 1) - K * np.exp(-r * T) * norm.cdf(d2, 0, 1))\n",
    "    elif type == 'put':\n",
    "        val = (K * np.exp(-r * T) * norm.cdf(-d2, 0, 1) - S_0 * norm.cdf(-d1, 0, 1))\n",
    "    else:\n",
    "        raise ValueError('Wrong input for type!')\n",
    "        \n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `black_scholes_analytical()` to value European call and put options with the parameters above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T20:09:33.579450Z",
     "start_time": "2020-01-27T20:09:33.574550Z"
    }
   },
   "outputs": [],
   "source": [
    "black_scholes_analytical(S_0=S_0, K=K, T=T, r=r, sigma=sigma, type='call')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use `simulate_gbm()` to simulate multiple price paths, then:\n",
    "\n",
    "1. Calculate the expected payoff as $max(S_T - K, 0)$\n",
    "1. Discount the expected payoff to $t=0$ using the risk-free rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T20:09:51.431159Z",
     "start_time": "2020-01-27T20:09:35.038351Z"
    }
   },
   "outputs": [],
   "source": [
    "gbm_simulations_2 = pd.DataFrame(simulate_gbm(s_0=S_0, mu=r, sigma=sigma, n_sims=N_SIMS, T=T, N=N).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the payoff of a European option?\n",
    "$$max(S_T - K, 0)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T20:09:51.506689Z",
     "start_time": "2020-01-27T20:09:51.470621Z"
    }
   },
   "outputs": [],
   "source": [
    "gbm_simulations_2.iloc[-1].sub(K).pipe(np.maximum, 0).mean() * discount_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two answers are very similar because they rely on the same assumptions:\n",
    "\n",
    "1. risk neutrality \n",
    "1. returns that are fully described by $\\mu$ and $\\sigma$\n",
    "\n",
    "Lewinson points out that we only need to simulate prices at expiration for European options.\n",
    "That is, we can set `N = 1` in `simulate_gbm()`.\n",
    "We will skip this exercise to save time, but you may want to review this exercise after class.\n",
    "\n",
    "We will skip pricing American options, because this is not a derivatives class.\n",
    "However, you may want to review this section after we finish this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Value-at-Risk using Monte Carlo\n",
    "\n",
    "> Value-at-risk is a very important financial metric that measures the risk associated with a position, portfolio, and so on. It is commonly abbreviated to VaR, not to be confused with Vector Autoregression. VaR reports the worst expected loss – at a given level of confidence – over a certain horizon under normal market conditions. The easiest way to understand it is by looking at an example. Let's say that the 1-day 95% VaR of our portfolio is \\\\$100. This means that 95\\% of the time (under normal market conditions), we will not lose more than \\\\$100 by holding our portfolio over one day.\n",
    "It is common to present the loss given by VaR as a positive (absolute) value. That is why in this example, a VaR of \\\\$100 means losing no more than $100.\n",
    ">\n",
    ">There are several ways to calculate VaR, some of which are:\n",
    ">\n",
    "> - Parametric Approach (Variance-Covariance)\n",
    "> - Historical Simulation Approach\n",
    "> - Monte Carlo simulations\n",
    ">\n",
    "> In this recipe, we only consider the last method. We assume that we are holding a portfolio consisting of two assets (Facebook and Google) and that we want to calculate a 1-day value-at-risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will follow Lewinson's approach and set a handful of parameters in the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T21:57:28.797956Z",
     "start_time": "2020-01-27T21:57:28.794731Z"
    }
   },
   "outputs": [],
   "source": [
    "RISKY_ASSETS = ['GOOG', 'META']\n",
    "SHARES = [5, 5]\n",
    "START_DATE = '2018-01-01'\n",
    "END_DATE = '2018-12-31'\n",
    "T = 1\n",
    "N_SIMS = 10 ** 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we will download all data from Yahoo! Finance, and use the start and end dates to subset our data later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T21:57:29.767168Z",
     "start_time": "2020-01-27T21:57:29.401221Z"
    }
   },
   "outputs": [],
   "source": [
    "df = yf.download(tickers=RISKY_ASSETS, session=session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we calculate daily returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T21:57:35.162794Z",
     "start_time": "2020-01-27T21:57:30.178438Z"
    }
   },
   "outputs": [],
   "source": [
    "returns = df['Adj Close'].pct_change().loc[START_DATE:END_DATE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need the variance-covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T21:57:35.325339Z",
     "start_time": "2020-01-27T21:57:35.314658Z"
    }
   },
   "outputs": [],
   "source": [
    "cov_mat = returns.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the variance-covariance matrix to calculate the Cholesky decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T21:57:35.535499Z",
     "start_time": "2020-01-27T21:57:35.530413Z"
    }
   },
   "outputs": [],
   "source": [
    "chol_mat = np.linalg.cholesky(cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chol_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Cholesky decomposition helps us generate random variables with the same variance and covariance as the observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T21:57:35.777195Z",
     "start_time": "2020-01-27T21:57:35.762352Z"
    }
   },
   "outputs": [],
   "source": [
    "rv = np.random.normal(size=(N_SIMS, len(RISKY_ASSETS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_rv = (chol_mat @ rv.T).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These random variables have a variance-covariance matrix similar to the real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cov(correlated_rv.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-21T22:21:12.139054Z",
     "start_time": "2019-09-21T22:21:12.128654Z"
    }
   },
   "source": [
    "Here are the parameters for the simulated price paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T21:57:35.981167Z",
     "start_time": "2020-01-27T21:57:35.976648Z"
    }
   },
   "outputs": [],
   "source": [
    "r = returns.mean().values\n",
    "sigma = returns.std().values\n",
    "S_0 = df['Adj Close'].iloc[-1].values\n",
    "P_0 = np.sum(SHARES * S_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate terminal prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T21:57:36.168799Z",
     "start_time": "2020-01-27T21:57:36.162491Z"
    }
   },
   "outputs": [],
   "source": [
    "S_T = S_0 * np.exp((r - 0.5 * sigma ** 2) * T + sigma * np.sqrt(T) * correlated_rv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-21T22:21:15.770057Z",
     "start_time": "2019-09-21T22:21:15.767478Z"
    }
   },
   "source": [
    "Calculate terminal portfolio values and returns.\n",
    "Note that these are dollar values, since VaR is typically expressed in dollar values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T21:57:36.388275Z",
     "start_time": "2020-01-27T21:57:36.383442Z"
    },
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "P_T = np.sum(SHARES * S_T, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_diff = P_T - P_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-21T22:21:18.834429Z",
     "start_time": "2019-09-21T22:21:18.831183Z"
    }
   },
   "source": [
    "Next, we calculate VaR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T21:57:36.609112Z",
     "start_time": "2020-01-27T21:57:36.594025Z"
    }
   },
   "outputs": [],
   "source": [
    "percentiles = [0.01, 0.1, 1.]\n",
    "var = np.percentile(P_diff, percentiles)\n",
    "\n",
    "for x, y in zip(percentiles, var):\n",
    "    print(f'1-day VaR with {100-x}% confidence: ${-y:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-21T22:21:21.518095Z",
     "start_time": "2019-09-21T22:21:21.514942Z"
    }
   },
   "source": [
    "Finally, we will plot VaR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T21:57:41.720953Z",
     "start_time": "2020-01-27T21:57:36.872561Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(P_diff, bins=100, density=True)\n",
    "ax.set_title('Distribution of 1-Day Changes in Portfolio Value\\n from ' + format(N_SIMS, ',') + ' Simulations')\n",
    "ax.axvline(x=var[2], color='red', ls='--')\n",
    "ax.text(x=var[2], y=1, s='99% 1-Day VaR', color='red', ha='right', va='top', rotation=90, transform=ax.get_xaxis_transform())\n",
    "ax.set_xlabel('1-Day Change in Portfolio Value ($)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "author": "Richard Herron",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "title": "Lewinson Chapter 6: Monte Carlo Simulations in Finance",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "396px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
