{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lewinson Chapter 7 - Asset Allocation in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Chapter 7 of Eryk Lewinson's [*Python for Finance Cookbook*](https://www.packtpub.com/product/python-for-finance-cookbook/9781789618518) covers portfolios returns and optimization.\n",
    "\n",
    "We will focus on:\n",
    "\n",
    "1. Evaluating $\\frac{1}{n}$ portfolios (i.e., equal-weighted portfolios)\n",
    "1. Using SciPy's optimizer to find the efficient frontier\n",
    "1. Using SciPy's optimizer to achieve any objective\n",
    "\n",
    "***Note:*** Indented block quotes are from Lewinson, and section numbers differ from Lewinson because we will not discuss every topic.\n",
    "\n",
    "I will simplify and streamline his code, where possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "%precision 4\n",
    "pd.options.display.float_format = '{:.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests_cache\n",
    "session = requests_cache.CachedSession(expire_after='1D')\n",
    "import yfinance as yf\n",
    "import pandas_datareader as pdr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the performance of a basic 1/n portfolio\n",
    "\n",
    "> We begin with inspecting the most basic asset allocation strategy: the 1/n portfolio. The idea is to assign equal weights to all the considered assets, thus diversifying the portfolio. As simple as that might sound, DeMiguel, Garlappi, and Uppal (2007) show that it can be difficult to beat the performance of the 1/n portfolio by using more advanced asset allocation strategies.\n",
    ">\n",
    "> The goal of the recipe is to show how to create a 1/n portfolio, calculate its returns, and then use a Python library called pyfolio to quickly obtain all relevant portfolio evaluation metrics in the form of a tear sheet. Historically, a tear sheet is a concise, usually one-page, document, summarizing important information about public companies.\n",
    "\n",
    "We will not use `pyfolio`, which appears to be abandoned.\n",
    "\n",
    "We will follow Lewinson's structure, although I prefer to download all data.\n",
    "These data are small (kilobytes instead of megabytes or gigabytes), so we might as well download all data then subset when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T22:39:57.697465Z",
     "start_time": "2020-01-27T22:39:57.694109Z"
    }
   },
   "outputs": [],
   "source": [
    "RISKY_ASSETS = ['AAPL', 'IBM', 'MSFT', 'TWTR']\n",
    "START_DATE = '2017-01-01'\n",
    "END_DATE = '2018-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T22:40:05.074684Z",
     "start_time": "2020-01-27T22:40:00.619657Z"
    }
   },
   "outputs": [],
   "source": [
    "df = yf.download(tickers=RISKY_ASSETS, session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T18:05:52.060088Z",
     "start_time": "2019-12-06T18:05:52.047752Z"
    }
   },
   "outputs": [],
   "source": [
    "returns = df['Adj Close'].pct_change().loc[START_DATE:END_DATE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do any portfolio math, we can make $\\frac{1}{n}$ portfolios \"by hand\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = 0.25*returns['AAPL'] + 0.25*returns['IBM'] + 0.25*returns['MSFT'] + 0.25*returns['TWTR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = 0.25 * returns.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(p1, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3 = returns.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(p1, p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note that when we apply the same portfolio weights every day, we rebalance at the same frequency as the returns data.***\n",
    "If we have daily data, rebalance daily.\n",
    "If we have monthly data, we rebalance monthly, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T18:05:52.066465Z",
     "start_time": "2019-12-06T18:05:52.063494Z"
    }
   },
   "outputs": [],
   "source": [
    "portfolio_weights = np.ones(returns.shape[1]) / returns.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I prefer a different notation to calculate returns.\n",
    "The following notation is more compact than Lewinson's notation and generates the same output.\n",
    "$$R_P = \\omega^T R,$$ where $R_P$ is a vector of portfolio returns, $\\omega$ is a vector of portfolio weights, and $R$ is a matrix of individual stock or asset returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T18:05:52.072256Z",
     "start_time": "2019-12-06T18:05:52.068898Z"
    }
   },
   "outputs": [],
   "source": [
    "portfolio_returns = returns.dot(portfolio_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(p1, portfolio_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some silly data to help understand the `.dot()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silly = pd.DataFrame(np.arange(8).reshape(2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silly.dot(portfolio_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silly_weights = np.array([1, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silly.dot(silly_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Efficient Frontier using Monte Carlo simulations\n",
    "\n",
    "> According to the Modern Portfolio Theory, the Efficient Frontier is a set of optimal portfolios in the risk-return spectrum. This means that the portfolios on the frontier:\n",
    "> \n",
    "> - Offer the highest expected return for a given level of risk\n",
    "> - Offer the lowest level of risk for a given level of expected returns\n",
    "> \n",
    "> All portfolios located under the Efficient Frontier curve are considered sub-optimal, so it is always better to choose the ones on the frontier instead.\n",
    "> \n",
    "> In this recipe, we show how to find the Efficient Frontier using Monte Carlo simulations. We build thousands of portfolios, using randomly assigned weights, and visualize the results. To do so, we use the returns of four US tech companies from 2018.\n",
    "\n",
    "We will skip Lewinson's Monte Carlo simulation of the efficient frontier.\n",
    "For some students, this simulation is enlightening.\n",
    "However, for many students, it creates bad habits.\n",
    "Therefore, we will jump right to using the optimizer to find the efficient frontier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Crash Course in scipy's minimize() Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sco.minimize()` function iteratively finds the input array `x` that minimizes the output of function `fun`.\n",
    "We pass our first guess for the input array `x` to the argument `x0=`.\n",
    "We pass additional arguments for the function `fun` as a tuple to the argument `args=`.\n",
    "We pass the lower and upper bounds on `x` as a tuple of tuples to the argument `bounds=`.\n",
    "We contrain our results with a tuple of dictionaries of functions to the argument`contraints=`.\n",
    "\n",
    "Here is a simple example that minimizes the `quadratic()` function $y = (x - a)^2$ where $a=5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T23:15:25.643290Z",
     "start_time": "2020-01-27T23:15:25.640591Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.optimize as sco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic(x, a=5):\n",
    "    return (x - a) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum output of `quadratic()` occurs at $x=5$ if we do not use bounds or constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sco.minimize(\n",
    "    fun=quadratic,\n",
    "    x0=np.array([2001])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum output of `quadratic()` occurs at $x=6$ if we bound `x` between 6 and 10 (i.e., $6 \\leq x \\leq 10$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sco.minimize(\n",
    "    fun=quadratic,\n",
    "    x0=np.array([2001]),\n",
    "    bounds=((6, 10),)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the minimum output of `quadratic()` occurs at $x=6$, again, if bound `x` between 5 and 10 and we constrain `x - 6` to be positive.\n",
    "We use bounds to simply limit the search space, and we use constraints when we need to limit the search based on some formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sco.minimize(\n",
    "    fun=quadratic,\n",
    "    x0=np.array([2001]),\n",
    "    bounds=((5, 10),),\n",
    "    constraints=({'type': 'ineq', 'fun': lambda x: x - 6})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use `sco.minimize()`s `args=` argument to to change the `a=` argument in `quadratic()`.\n",
    "Note that `args=` expects a tuple, so we need a trailing comma `,` if we only have one argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sco.minimize(\n",
    "    fun=quadratic,\n",
    "    args=(20,),\n",
    "    x0=np.array([2001]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Efficient Frontier using optimization with scipy\n",
    "\n",
    "> In the previous recipe, Finding the Efficient Frontier using Monte Carlo simulations, we used a brute-force approach based on Monte Carlo simulations to visualize the Efficient Frontier. In this recipe, we use a more refined method to determine the frontier.\n",
    "> \n",
    "> From its definition, the Efficient Frontier is formed by a set of portfolios offering the highest expected portfolio return for a certain volatility, or offering the lowest risk (volatility) for a certain level of expected returns. We can leverage this fact, and use it in numerical optimization. The goal of optimization is to find the best (optimal) value of the objective function by adjusting the target variables and taking into account some boundaries and constraints (which have an impact on the target variables). In this case, the objective function is a function returning portfolio volatility, and the target variables are portfolio weights.\n",
    "> \n",
    "> Mathematically, the problem can be expressed as: $$\\min \\omega^T \\Sigma \\omega$$ s.t. $$\\omega^T \\textbf{1} = 1$$ $$\\omega \\geq 0$$ $$\\omega^T \\mu = \\mu_P$$\n",
    ">\n",
    "> Here, $\\omega$ is a vector of weights, $\\Sigma$ is the covariance matrix, $\\mu$ is a vector of returns, $\\mu_P$ and is the expected portfolio return.\n",
    "> \n",
    "> We iterate the optimization routine used for finding the optimal portfolio weights over a range of expected portfolio returns, and this results in the Efficient Frontier.\n",
    "\n",
    "We optimize our portfolios (i.e., minimize portfolio variance subject to contraints) with SciPy's optimize module.\n",
    "However, we will not use Lewinson's helper functions.\n",
    "Lewinson's approach is computationally efficient, but requires us to manage different $\\mu$ (mean return vector) and $\\Sigma$ (variance-covariance matrix) for every sample we want to consider.\n",
    "Instead, we will base our helper functions on weights and returns only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def port_std(w, rs):\n",
    "    return np.sqrt(252) * rs.dot(w).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_mv = sco.minimize(\n",
    "    fun=port_std, # we want to minimize portfolio volatility\n",
    "    x0=np.ones(returns.shape[1]) / returns.shape[1], # x0 contains our first guess at portfolio weights\n",
    "    args=(returns, ), # args provides additional argument to the function we will minimize\n",
    "    bounds=((0, 1), (0, 1), (0, 1), (0, 1)), # bounds limits the search space for portfolio weights\n",
    "    constraints=(\n",
    "        {'type': 'eq', 'fun': lambda x: x.sum() - 1} # \"eq\" constraints are driven to zero\n",
    "    )\n",
    ")\n",
    "assert res_mv['success']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_mv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the attributes of this minimum variance portfolio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_port_res(w, title, df=returns):\n",
    "    print(\n",
    "        title,\n",
    "        '=' * len(title),\n",
    "        '',\n",
    "        'Performance',\n",
    "        '-----------',\n",
    "        'Return:       {:0.4f}'.format(252 * df.dot(w).mean()),\n",
    "        'Volatility:   {:0.4f}'.format(np.sqrt(252) * df.dot(w).std()),\n",
    "        '',\n",
    "        sep='\\n'\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        'Weights', \n",
    "        '-------', \n",
    "        sep='\\n'\n",
    "    )\n",
    "    for i, j in zip(df.columns, w):\n",
    "        print((i + ':').ljust(14) + '{:0.4f}'.format(j))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_port_res(res_mv['x'], 'Minimum Variance Portfolio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use these skills to map the efficient frontier in class.\n",
    "Here are some tips:\n",
    "\n",
    "1. Loop over a set of target returns from the best to worst\n",
    "1. Use each target return as a constraint to `sco.minimize()`\n",
    "1. Save your portfolio weights, returns, and volatilities to a data frame named `ef`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Practice:***\n",
    "Write functions for the following performance measures that Lewinson discusses:\n",
    "\n",
    "> - Sharpe ratio: One of the most popular performance evaluation metrics, it measures the excess return (over the risk-free rate) per unit of standard deviation. When no risk-free rate is provided, the default assumption is that it is equal to 0%. The greater the Sharpe ratio, the better the portfolio's risk-adjusted performance.\n",
    "> - Max drawdown: A metric of the downside risk of a portfolio, it measures the largest peak-to-valley loss (expressed as a percentage) during the course of the investment. The lower the maximum drawdown, the better.\n",
    "> - Calmar ratio: The ratio is defined as the average annual compounded rate of return divided by the maximum drawdown for that same time period. The higher the ratio, the better.\n",
    "> - Stability: Measured as the R-squared of a linear fit to the cumulative log returns. In practice, this means regressing a range of integers (serving as the time index) on cumulative log returns.\n",
    "> - ~~Omega ratio: The probability-weighted ratio of gains over losses for a determined return target threshold (default set to 0). Its main advantage over the Sharpe ratio is that the Omega ratio—by construction—considers all moments of the returns distribution, while the former only considers the first two (mean and variance).~~\n",
    "> - Sortino ratio: A modified version of the Sharpe ratio, where the standard deviation in the denominator is replaced with downside deviation.\n",
    "> - Skew: Skewness measures the degree of asymmetry, that is, how much is the given distribution (here, of portfolio returns) more skewed than the Normal distribution. Negative skewness (left-skewed distributions) means  that large negative returns occur more frequently than large positive ones.\n",
    "> - Kurtosis: Measures extreme values in either of the tails. Distributions with large kurtosis exhibit tail data exceeding the tails of the Gaussian distribution, meaning that large and small returns occur more frequently.\n",
    "> - Tail ratio: The ratio (absolute) between the 95th and 5th percentile of the daily returns. A tail ratio of ~0.8 means that losses are ~1.25 times as bad as profits.\n",
    "> - Daily value at risk: Calculated as $\\mu - 2\\sigma$, where $\\mu$ is the average portfolio return over the period, and $\\sigma$ the corresponding standard deviation.\n",
    "\n",
    "Here are some tips:\n",
    "\n",
    "1. Write functions that return decimal returns\n",
    "1. For performance measures with benchmarks or targets, set the default to the risk-free rate of return from Ken French\n",
    "1. Call these functions the lower-case version of the entry name with underscores instead of spaces\n",
    "\n",
    "Also add:\n",
    "\n",
    "1. Total return\n",
    "1. Annual geometric mean return\n",
    "1. Annual volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Practice:***\n",
    "Write a `tear_sheet()` function that tabulates average annual returns, cumulative returns, annual volatility, and the performance measures in the previous practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Practice:***\n",
    "Find the portfolio with the maximum Sharpe Ratio for a portfolio of FAANG stocks from 2010 to 2019.\n",
    "Note that `sco.minimize()` finds *minimums*, so you need to minimize the *negative* Sharpe Ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Practice:***\n",
    "What is the *out-of-sample* performance of this maximum Sharpe Ratio portfolio?\n",
    "For example, what is the Sharpe Ratio of this portfolio from 2020 through today?\n",
    "How does this compare to the Sharpe Ratio of the $1/N$ portfolio?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Practice:***\n",
    "Find the portfolio with the maximum Sharpe Ratio for a portfolio of FAANG stocks from 2010 to 2019, but allow short positions up to 30% of the portfolio.\n",
    "So for every one dollar invested, you can short one or more of these four stocks to finance another 30 cents."
   ]
  }
 ],
 "metadata": {
  "author": "Richard Herron",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "title": "Lewinson Chapter 7 - Asset Allocation in Python",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
